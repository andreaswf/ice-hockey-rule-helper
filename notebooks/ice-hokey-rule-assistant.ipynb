{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be214828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader, PDFMinerLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# openAI embeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# vector store\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# load api keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d648d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document and document loaders\n",
    "#file_path = \"../documents/2025-26_iihf_rulebook.pdf\"\n",
    "\n",
    "#loader = PDFMinerLoader(file_path=file_path, mode='single', pages_delimiter='\\n-------THIS IS A CUSTOM END OF PAGE-------\\n')\n",
    "\n",
    "#docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502fea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document and document loaders\n",
    "file = \"../documents/2025-26_iihf_rulebook.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for i, d in enumerate(docs, start=1):\n",
    "    d.metadata['source'] = \"IIHF Rulebook 2025-26\"\n",
    "    \n",
    "docs_cropped = docs[15:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2d1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "for i, d in enumerate(docs_cropped, start=1):\n",
    "    parts.append(f\"\\n\\n<<<PAGE {i}>>>\\n{d.page_content.strip()}\")\n",
    "\n",
    "merged_text = \"\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3e18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_doc = Document(\n",
    "    page_content=merged_text,\n",
    "    metadata={\n",
    "        \"source\": \"IIHF Rulebook 2025-26\",\n",
    "        \"page_count\": len(docs_cropped),\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "60758bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sets the rule splitter, splitting on each individual rule in the rulebook\n",
    "\n",
    "outer_rule_sep = r\"RULE[ \\u00A0]+\\d{1,3}[ \\u00A0]+[A-Z]+(?:[ \\u00A0][A-Z]+)*\"\n",
    "\n",
    "rule_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[outer_rule_sep],\n",
    "    chunk_size=1600,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    "    keep_separator=True,\n",
    "    is_separator_regex=True\n",
    ")\n",
    "\n",
    "rule_splits = rule_splitter.split_documents([merged_doc])\n",
    "len(rule_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a458bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the overall rule used as metadata\n",
    "\n",
    "rule_pattern = re.compile(r\"RULE[ \\u00A0]+\\d{1,3}[ \\u00A0]+[A-Z]+(?:[ \\u00A0][A-Z]+)*\")\n",
    "\n",
    "for chunk in rule_splits:\n",
    "    match = rule_pattern.search(chunk.page_content)\n",
    "    if match:\n",
    "        rule = match.group(0).strip()\n",
    "        chunk.metadata[\"rule\"] = rule\n",
    "    else:\n",
    "        chunk.metadata[\"rule\"] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "eb0a66c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_rule_sep = r\"\\d{1,3}\\.\\d{1,2}\\.\\s+[A-Z]+(?:[ \\u00A0][A-Z\\-]+)*\"\n",
    "\n",
    "inner_rule_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[inner_rule_sep],\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=80,\n",
    "    add_start_index=True,\n",
    "    keep_separator=True,\n",
    "    is_separator_regex=True\n",
    ")\n",
    "\n",
    "inner_rule_splits = inner_rule_splitter.split_documents(rule_splits)\n",
    "len(inner_rule_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f5dc9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the inner rule used as metadata\n",
    "\n",
    "inner_rule_pattern = re.compile(r\"\\d{1,3}\\.\\d{1,2}\\.\\s+[A-Z]+(?:[ \\u00A0][A-Z\\-]+)*\")\n",
    "\n",
    "for chunk in inner_rule_splits:\n",
    "    match = inner_rule_pattern.search(chunk.page_content)\n",
    "    if match:\n",
    "        rule = match.group(0).strip()\n",
    "        chunk.metadata[\"inner_rule\"] = rule\n",
    "    else:\n",
    "        chunk.metadata[\"inner_rule\"] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "aadaccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0997b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "vector_store = FAISS.from_documents(documents=inner_rule_splits, embedding=embeddings)\n",
    "vector_store.save_local(\"vs_faiss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "f235fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You are an ice hockey rule assistant.\n",
    "\n",
    "Follow these rules:\n",
    "- Answer ONLY using the provided context below. If the answer is unknown or not in the context, say \"I don't know\".\n",
    "- Be concise and use bullet points.\n",
    "- After each bullet, include a citation using the metadata field: rule: <inner_rule>).\n",
    "- Do not use outside knowledge.\n",
    "\n",
    "You must format the answer as:\n",
    "• <point> (rule: <inner_rule>)\n",
    "• <point> (rule: <inner_rule>)\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"system\", \"Context (use only what is inside the markers):\\n---\\n{context}\\n---\"),\n",
    "    (\"user\", \"{question}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c749adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formattigng for what the llm recieves in context\n",
    "def format_docs(docs):\n",
    "    formatted_doc = []\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        rule = d.metadata.get(\"rule\", \"N/A\")\n",
    "        inner = d.metadata.get(\"inner_rule\", \"N/A\")\n",
    "        formatted_doc.append(\n",
    "            f\"[{i}] Rule: {rule} | Inner: {inner}\\n{d.page_content.strip()}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(formatted_doc)\n",
    "    \n",
    "\n",
    "# initalize retriver and llm\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "    \n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "    }\n",
    "| prompt_template \n",
    "| llm \n",
    "| StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "63b7d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• A minor penalty for an infraction like tripping or slashing can lead to a penalty shot if the infraction occurs when the puck is in the goal crease. (rule: 63.6)\n",
      "• If a player's action causes a penalty shot, the minor penalty associated with that infraction will not be served unless it is a major or misconduct penalty. (rule: 24.6)\n"
     ]
    }
   ],
   "source": [
    "question = \"When is a minor penalty like tripping or slashing a penaly shot instead?\"\n",
    "print(rag_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
